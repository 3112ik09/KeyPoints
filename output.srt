1
00:00:00,000 --> 00:00:02,720
When you ask the large language model a question,

2
00:00:02,720 --> 00:00:04,520
it is important that it retrieves

3
00:00:04,520 --> 00:00:07,320
the most relevant information to answer it.

4
00:00:07,320 --> 00:00:11,080
This is otherwise known as retrieval augmented generation.

5
00:00:11,080 --> 00:00:12,480
For example, when you ask

6
00:00:12,480 --> 00:00:14,640
Chatchapiti what the name of your dog is,

7
00:00:14,640 --> 00:00:16,200
it has no clue.

8
00:00:16,200 --> 00:00:18,400
But if you feed it the data that is

9
00:00:18,400 --> 00:00:20,520
in stored in your vector database,

10
00:00:20,520 --> 00:00:25,160
and maybe you specify that Erica has a dog and her name is Bowen,

11
00:00:25,160 --> 00:00:27,200
Chatchapiti is able to retrieve

12
00:00:27,200 --> 00:00:30,320
that relevant context and properly answer your question.

13
00:00:30,320 --> 00:00:32,520
In this video, I'll go over how you can

14
00:00:32,520 --> 00:00:37,280
chunk your text data to ensure that the language model is one,

15
00:00:37,280 --> 00:00:40,280
receiving the most relevant information,

16
00:00:40,280 --> 00:00:43,240
maybe instead of feeding it the whole PDF document,

17
00:00:43,240 --> 00:00:44,760
you feed it by elements,

18
00:00:44,760 --> 00:00:46,240
which I have a visual for,

19
00:00:46,240 --> 00:00:49,520
and then two, you don't want to go over the context window,

20
00:00:49,520 --> 00:00:52,520
and this is dependent on which model that you are using.

21
00:00:52,520 --> 00:00:54,160
Starting with the text splitter.

22
00:00:54,200 --> 00:00:57,240
So what this does is it takes the PDF document,

23
00:00:57,240 --> 00:00:59,720
which we have here on the left-hand side,

24
00:00:59,720 --> 00:01:03,400
and it takes the chunks depending on the model

25
00:01:03,400 --> 00:01:05,440
or the chunk size that you defined.

26
00:01:05,440 --> 00:01:12,120
So for example, GPT 3.5 Turbo 16K has a 16,000 token window,

27
00:01:12,120 --> 00:01:16,840
but other models have either a smaller or larger window size.

28
00:01:16,840 --> 00:01:19,640
So just what this is doing is just splitting up the text

29
00:01:19,640 --> 00:01:21,040
once it hits that limit,

30
00:01:21,040 --> 00:01:24,720
and then boom, we have chunk one, which is the blue text,

31
00:01:24,720 --> 00:01:28,320
and then it moves right on to the green window,

32
00:01:28,320 --> 00:01:30,000
which is the next chunk.

33
00:01:30,000 --> 00:01:33,960
The rolling window complements the text splitter extremely well,

34
00:01:33,960 --> 00:01:37,040
and this is because once chunk one is finished,

35
00:01:37,040 --> 00:01:41,400
chunk two will begin with a few tokens or characters

36
00:01:41,400 --> 00:01:43,680
that is included in chunk one.

37
00:01:43,680 --> 00:01:46,800
So in this example, you can see the blue text

38
00:01:46,840 --> 00:01:51,560
from this document is the beginning or the start of chunk two,

39
00:01:51,560 --> 00:01:54,040
and this is very important in documents

40
00:01:54,040 --> 00:01:57,200
where the second sentence doesn't make sense

41
00:01:57,200 --> 00:02:00,840
because it doesn't have the information from sentence one.

42
00:02:00,840 --> 00:02:04,000
Lama index, Lang chain, and Haystack,

43
00:02:04,000 --> 00:02:07,400
they all three have this implemented in their frameworks,

44
00:02:07,400 --> 00:02:08,680
and at the end of this video,

45
00:02:08,680 --> 00:02:11,560
I'll share it with you with the link to the documentation

46
00:02:11,560 --> 00:02:13,000
so you can test this out for yourself.

47
00:02:13,000 --> 00:02:15,840
Moving on to how you would chunk PDF documents.

48
00:02:15,880 --> 00:02:18,440
So previously, Chukrin I partnered up

49
00:02:18,440 --> 00:02:20,800
on creating a demo for unstructured.

50
00:02:20,800 --> 00:02:23,640
So what we did was we ingested PDF documents,

51
00:02:23,640 --> 00:02:25,800
which were two research papers,

52
00:02:25,800 --> 00:02:28,600
and then we chunked it by the elements,

53
00:02:28,600 --> 00:02:30,160
which unstructured has.

54
00:02:30,160 --> 00:02:32,440
And if you haven't used unstructured before,

55
00:02:32,440 --> 00:02:36,320
I highly recommend checking it out along with Lama index.

56
00:02:36,320 --> 00:02:40,160
So what it is doing is it takes the PDF heading.

57
00:02:40,160 --> 00:02:42,240
So in this example, I have the abstract,

58
00:02:42,240 --> 00:02:43,800
introduction, and related work.

59
00:02:43,800 --> 00:02:46,680
So each section will have its own chunk.

60
00:02:46,680 --> 00:02:49,720
And this is very important when making queries

61
00:02:49,720 --> 00:02:51,840
that are specific to title.

62
00:02:51,840 --> 00:02:55,280
So this is that kind of semantic region of searching.

63
00:02:55,280 --> 00:02:57,520
And maybe you'd have like the abstract property,

64
00:02:57,520 --> 00:02:59,520
introduction, property, et cetera.

65
00:02:59,520 --> 00:03:01,080
And this is one way to make sure

66
00:03:01,080 --> 00:03:04,000
that you have extremely relevant information.

67
00:03:04,000 --> 00:03:06,400
If you're interested in using unstructured

68
00:03:06,400 --> 00:03:09,960
with Lama index, so if you start typing in unstructured,

69
00:03:09,960 --> 00:03:13,080
you can find the file loader here.

70
00:03:13,080 --> 00:03:16,000
And this is where you can ingest TXT files,

71
00:03:16,000 --> 00:03:18,280
doc, PowerPoint, JPEG, all of it.

72
00:03:18,280 --> 00:03:21,480
Then moving on to the Lama index node parser.

73
00:03:21,480 --> 00:03:24,000
So this is where you would define that chunk size

74
00:03:24,000 --> 00:03:27,160
that I talked about, and then also the chunk overlap.

75
00:03:27,160 --> 00:03:30,240
So with this chunk overlap of 20 tokens,

76
00:03:30,240 --> 00:03:33,120
it is taking the 20 tokens from the previous chunk

77
00:03:33,120 --> 00:03:35,080
into the following chunk.

78
00:03:35,080 --> 00:03:37,160
And this is a lane chain documentation

79
00:03:37,160 --> 00:03:39,640
on where they have their text splitters.

80
00:03:39,640 --> 00:03:42,960
So they have, I believe, code on how to do this.

81
00:03:42,960 --> 00:03:46,640
And maybe if you want to split the text by the new lines

82
00:03:46,640 --> 00:03:50,800
or also the chunk overlap and the chunk size as well.

83
00:03:50,800 --> 00:03:53,080
And then ending with haystack.

84
00:03:53,080 --> 00:03:55,200
They have the chunk size,

85
00:03:55,200 --> 00:03:58,240
and then again the split overlap.

86
00:03:58,240 --> 00:03:59,760
So you can check that out.

87
00:03:59,760 --> 00:04:03,360
And then I want to end this video

88
00:04:03,360 --> 00:04:06,960
with recommending you join the Arise workshop

89
00:04:06,960 --> 00:04:09,920
that I will be hosting along with Aman from Arise

90
00:04:09,920 --> 00:04:11,600
and Ronnie from Unstructured.

91
00:04:11,640 --> 00:04:14,400
We will be exploring the chunking techniques

92
00:04:14,400 --> 00:04:18,120
and re-ranking for enhancing your retrieval

93
00:04:18,120 --> 00:04:21,040
and the results in your FAG application.

94
00:04:21,040 --> 00:04:22,840
I hope you guys are able to join.

95
00:04:22,840 --> 00:04:24,280
And I'll see you next time.

96
00:04:24,280 --> 00:04:25,120
Bye.

